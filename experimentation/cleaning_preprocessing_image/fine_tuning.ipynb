{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dhMRI3HaWqBn",
        "outputId": "0fe1a2b0-39f5-407d-b2e2-d79dfe93e04f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from sklearn.preprocessing import normalize"
      ],
      "metadata": {
        "id": "cjBlAWL5YSHt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Extraccion archivo desde google drive, configuracion general (directorios y parámetros)"
      ],
      "metadata": {
        "id": "-m7kVaY3-gY6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8H7RQfE8YN7P",
        "outputId": "182ffa0e-c09a-4560-9c36-f1870e4fdef1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = \"/content/drive/MyDrive/data\"\n",
        "TRAIN_DIR = f\"{DATA_DIR}/train\"\n",
        "VAL_DIR = f\"{DATA_DIR}/test\"\n",
        "IMG_PATH = f\"{DATA_DIR}/soir_bleu.jpg\"\n",
        "EMBED_PATH = f\"{DATA_DIR}/soir_bleu_embedding.npy\""
      ],
      "metadata": {
        "id": "kL8SHpvIXsY4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = (224, 224)"
      ],
      "metadata": {
        "id": "4ddiAFD3YYsK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Estrategia TPU"
      ],
      "metadata": {
        "id": "x9puaT3h-eKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.TPUStrategy(tpu)\n",
        "    print(\"✅ TPU activado\")\n",
        "except ValueError:\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "    print(\"⚠️ TPU no encontrado, usando CPU/GPU\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAPLywUoyZzh",
        "outputId": "421c3ff1-7916-4586-f3d5-b661e23ae196"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ TPU no encontrado, usando CPU/GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset mediante carga de datos"
      ],
      "metadata": {
        "id": "7Vi4AzC7-vJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    TRAIN_DIR,\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    label_mode='categorical'\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    VAL_DIR,\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    label_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "id": "kKrgIzGgYcMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_ds.class_names\n",
        "num_classes = len(class_names)\n",
        "print(f\"Clases: {class_names}\")"
      ],
      "metadata": {
        "id": "sThDHbX8x_fh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocesar\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "def preprocess(image, label):\n",
        "    return preprocess_input(image), label\n",
        "\n",
        "train_ds = train_ds.map(preprocess).prefetch(AUTOTUNE)\n",
        "val_ds = val_ds.map(preprocess).prefetch(AUTOTUNE)"
      ],
      "metadata": {
        "id": "fCszvnbZxlSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Callbacks"
      ],
      "metadata": {
        "id": "6IKpqzJj-81Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-6)\n",
        "checkpoint = ModelCheckpoint(\"efficientnet_tuneaito.h5\", monitor='val_loss', save_best_only=True)"
      ],
      "metadata": {
        "id": "rdfxIJi26rm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Declaramos la inicializacion del modelo"
      ],
      "metadata": {
        "id": "hkln_f3s_B9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "    base_model = tf.keras.applications.EfficientNetB0(\n",
        "        include_top=False, weights='imagenet', input_shape=(224, 224, 3)\n",
        "    )\n",
        "    base_model.trainable = False\n",
        "\n",
        "    inputs = tf.keras.Input(shape=(224, 224, 3))\n",
        "    x = base_model(inputs, training=False)\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
        "    x = tf.keras.layers.Dropout(0.5)(x)\n",
        "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "RSwHilzFYjdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Primera parte del entrenamiento (base)"
      ],
      "metadata": {
        "id": "h52fH38y_Pvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_ds, validation_data=val_ds, epochs=5, callbacks=[early_stop, reduce_lr, checkpoint])"
      ],
      "metadata": {
        "id": "sDNtjrd5AZb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aplicamos fine-tuning"
      ],
      "metadata": {
        "id": "QGHQwgHB_ZAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:-30]:\n",
        "  layer.trainable = False\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history_fine = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    initial_epoch=5,\n",
        "    epochs=15,\n",
        "    callbacks=[early_stop, reduce_lr, checkpoint]\n",
        ")"
      ],
      "metadata": {
        "id": "JBg53o9jYnjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model(\"efficientnet_tuneaito.h5\")\n",
        "embedding_model = tf.keras.Model(inputs=model.input, outputs=model.layers[-3].output)"
      ],
      "metadata": {
        "id": "KzRlj9KX9CG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_model.save(f\"{DATA_DIR}/efficientnet_tuneaito.h5\")"
      ],
      "metadata": {
        "id": "gywHl-H0A5mW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PUESTA A PRUEBA DEL MODELO\n",
        " Extraccion de características desde el modelo mejorado con el nuevo dataset"
      ],
      "metadata": {
        "id": "yVfVOnBlAAcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = load_img(IMG_PATH, target_size=IMG_SIZE)\n",
        "img_array = img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array = preprocess_input(img_array)\n",
        "\n",
        "embedding = embedding_model.predict(img_array)\n",
        "embedding = normalize(embedding)\n",
        "\n",
        "np.save(EMBED_PATH, embedding)\n",
        "print(f\"✅ Embedding guardado en: {EMBED_PATH}\")"
      ],
      "metadata": {
        "id": "FKXa9ZAiYpXk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}