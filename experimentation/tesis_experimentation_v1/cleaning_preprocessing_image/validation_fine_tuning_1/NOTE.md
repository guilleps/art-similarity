### âœ… **Resumen de Resultados por Fase**

#### ğŸ“Œ **Fase 1 (Feature Extraction)**

* Buen comienzo: la red logra entrenar con pesos congelados y obtiene una **accuracy de validaciÃ³n de \~66.5%** en la mejor Ã©poca.
* El modelo guardado (`efficientnet_phase1.keras`) se hace correctamente.

#### ğŸ“Œ **Fase 2 (Fine-Tuning parcial desde capa 50)**

* **Decay de accuracy**: la validaciÃ³n baja progresivamente de \~62% a 59%, lo cual sugiere que al descongelar 50 capas sin una tasa de aprendizaje suficientemente baja, el modelo sobreajustÃ³ o destruyÃ³ parte del conocimiento previo.
* El LR scheduler fue aplicado, pero iniciar con `1e-4` puede haber sido demasiado alto para tantas capas.

#### ğŸ“Œ **Fase 3 (Fine-Tuning total)**

* AquÃ­ sÃ­ se usÃ³ una LR mÃ¡s conservadora `1e-5`, lo cual ayudÃ³ a estabilizar, pero:

  * La accuracy no mejora mÃ¡s allÃ¡ de \~59%.
  * Indica que el modelo ya no estÃ¡ aprendiendo cosas nuevas, o que las capas iniciales no estaban suficientemente Ãºtiles para las nuevas clases.

#### ğŸ“Œ **EvaluaciÃ³n Embeddings**

* Se logrÃ³ calcular el **Silhouette Score** y el **Precision\@5**:

  ```
  Silhouette=0.1090, P@5=0.5162
  ```

  * El `P@5=51.6%` estÃ¡ bastante bien considerando que hay 10 clases.
  * Pero el `Silhouette Score=0.1090` es bajo â†’ indica que las clases estÃ¡n poco separadas en el espacio de embeddings.

---

### ğŸ“‰ Posibles Problemas Detectados

1. **ResoluciÃ³n de imagen (260x260)**:

   * No es problema que tus imÃ¡genes reales sean de 256x256 y luego se reescalen a 260x260.
   * Sin embargo, estÃ¡s interpolando cada imagen, lo que podrÃ­a estar suavizando detalles importantes de estilo (clave si estÃ¡s analizando imÃ¡genes artÃ­sticas).
   * **ğŸ‘‰ RecomendaciÃ³n**: prueba con imÃ¡genes en su tamaÃ±o original (256x256) usando `EfficientNetB0` o recorta inteligentemente las imÃ¡genes a 260x260 en lugar de escalarlas.

2. **Pocas Ã©pocas**:

   * 3 Ã©pocas por fase es muy poco para una tarea de fine-tuning.
   * En Fase 1, se nota que el modelo seguÃ­a mejorando.
   * **ğŸ‘‰ RecomendaciÃ³n**: al menos 5-10 Ã©pocas por fase para capturar patrones, especialmente si usas EarlyStopping.

3. **Cantidad de capas descongeladas (50)**:

   * Es una cantidad significativa (mÃ¡s del 60% del modelo), lo cual exige una tasa de aprendizaje muy pequeÃ±a y un entrenamiento mÃ¡s largo.
   * **ğŸ‘‰ RecomendaciÃ³n**: intenta descongelar primero desde block7 Ãºnicamente (las Ãºltimas 20-30 capas) y monitorea el cambio.

4. **Embeddings poco separables**:

   * El bajo Silhouette indica que no se estÃ¡n aprendiendo representaciones suficientemente discriminativas.
   * Puede deberse a:

     * Dataset pequeÃ±o o muy homogÃ©neo.
     * Arquitectura no suficientemente profunda para capturar diferencias compositivas.
     * Embedding layer demasiado pequeÃ±o (`128`).
   * **ğŸ‘‰ RecomendaciÃ³n**:

     * Probar `EMBEDDING_DIM=256` o `512`.
     * AÃ±adir `BatchNormalization` justo despuÃ©s del `GlobalAveragePooling2D` o antes del embedding.

5. **Dataset**:

   * Mencionas que usas 5000 imÃ¡genes en train y `test/` (sin indicar cuÃ¡ntas).
   * **ğŸ‘‰ RecomendaciÃ³n**: asegurarte de que el test dataset tenga al menos 100-200 imÃ¡genes por clase.

---

### âœ… Siguientes pasos recomendados

1. **Cambios para el prÃ³ximo experimento**:

   * `IMG_SIZE = (256, 256)`
   * `EPOCHS_PHASE1 = 5`, `EPOCHS_PHASE2 = 5`, `EPOCHS_PHASE3 = 5`
   * Reducir capas descongeladas en Fase 2: `trainable_layers=20`
   * `EMBEDDING_DIM = 256`
   * AÃ±adir `BatchNormalization()` despuÃ©s del pooling y antes del `Dense(embedding)`
   * Usar `CosineDecay` o `Warmup` como scheduler opcional

2. **Para evaluar resultados de forma mÃ¡s visual**:

   * Haz un `TSNE` o `PCA` de los embeddings para visualizar si las clases se agrupan.
   * Muestra ejemplos de errores en `Precision@5` para ver si son visualmente similares.