{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "GIwjDgV81OUG",
        "ltByPXHP1bEv",
        "t0sK1Nl819El",
        "GkbyNWfV2FWB",
        "4NdW2BNQ2KkJ",
        "i_vSO7hm2dQ-",
        "qcrlAB7H2ww3",
        "clIySuAo3EPw",
        "oqaul23T3Ou4"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## CNN: EfficientNetB2\n",
        "![EfficientNet-B2](https://viso.ai/wp-content/uploads/2024/03/EfficientNet-Architecture-diagram.png)\n",
        "* Fuente: https://viso.ai/deep-learning/efficientnet/"
      ],
      "metadata": {
        "id": "tpf3wqZ83h8b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### IMPORTAMOS LIBRERIAS"
      ],
      "metadata": {
        "id": "GIwjDgV81OUG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wa73ks740wIR"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks\n",
        "from tensorflow.keras.applications import EfficientNetB2\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import numpy as np\n",
        "import sys\n",
        "import datetime\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CONFIGURACIÓN GENERAL (HIPERPARAMETROS) util dado la\n",
        "interpolacion de las variables constantes, simplifica el input pero puedes perder fine-grained style information\n",
        "\n",
        "*   Tamaño de batch: necesario encontrar un balance entre el costo computacional y la estabilidad de gradientes\n",
        "*   Resolución por imágenes (256x256) [Art-Bench-10](https://github.com/liaopeiyuan/artbench)\n",
        "*   Cantidad de epocas por fase 1, 2 y 3.\n"
      ],
      "metadata": {
        "id": "ltByPXHP1bEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = (256, 256) # 256x256 por pruebas\n",
        "EPOCHS_PHASE1 = 5\n",
        "EPOCHS_PHASE2 = 5\n",
        "EPOCHS_PHASE3 = 5\n",
        "EMBEDDING_DIM = 256"
      ],
      "metadata": {
        "id": "UfKysU_n0zyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DATASET LOADING\n",
        "Se cargan datasets de entrenamiento y prueba desde directorios, usando etiquetas enteras.\n",
        "\n",
        "> Importante, prefetch() y AUTOTUNE: realiza en paralelo el procesamiento de data (test/train), además del AUTOTUNE, ayuda a obtener el número óptimo de batches a preprocesar en paralelo\n",
        "\n"
      ],
      "metadata": {
        "id": "t0sK1Nl819El"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_datasets():\n",
        "    train_ds = image_dataset_from_directory(\n",
        "        \"C:/workspace/data/train_sampled\", # 5000 imagenes\n",
        "        image_size=IMG_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        label_mode='int',\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    test_ds = image_dataset_from_directory(\n",
        "        \"C:/workspace/data/test\",\n",
        "        image_size=IMG_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        label_mode='int',\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    return train_ds.prefetch(tf.data.AUTOTUNE), test_ds.prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "uI_WawfR04T0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AUGMENTACIÓN\n",
        "Al aumentar la data, debido a la falta de recursos para el entrenamineto lo que realizamos es generar variaciones de manera distintas a partir de las ingresadas, lo que mejora la generalización del modelo frente a variaciones pequeñas de estilo, manteniendo coherencia semántica."
      ],
      "metadata": {
        "id": "GkbyNWfV2FWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),  # simula reflejo horizontal\n",
        "    layers.RandomRotation(0.05),  # aplica rotaciones pequeñas, evitando la distorsion de estilo\n",
        "    layers.RandomZoom(height_factor=0.1, width_factor=0.1),  # escalar levemente\n",
        "    layers.Lambda(preprocess_input)  # importante: normalizar valores, asi comprende mejor el modelo\n",
        "], name=\"data_augmentation\")"
      ],
      "metadata": {
        "id": "f5ii_xBW07AL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MODELO BASE\n",
        "El modelo se construye sin la cabeza superior, la cual es la que define el final o el enfoque de clasificación de imagenes con una. Si trainable_layers=None, se congela toda la red."
      ],
      "metadata": {
        "id": "4NdW2BNQ2KkJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(trainable_layers=None):\n",
        "    base_model = EfficientNetB2(include_top=False, weights='imagenet', input_shape=(*IMG_SIZE, 3))\n",
        "    base_model.trainable = trainable_layers is not None\n",
        "\n",
        "    if trainable_layers:\n",
        "        for layer in base_model.layers[:-trainable_layers]:\n",
        "            layer.trainable = False  # solo entrenamos la parte final del backbone (forma de referenciar la arquitectura o cuerpo interno de la red)\n",
        "\n",
        "    inputs = layers.Input(shape=(*IMG_SIZE, 3))\n",
        "    x = data_augmentation(inputs)\n",
        "    x = base_model(x, training=False)\n",
        "    x = layers.GlobalAveragePooling2D()(x) # reduccion del mapa de caracteristicas\n",
        "    x = layers.BatchNormalization()(x) # durante el entrenamiento impacta más con su estabilizacion\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    embeddings = layers.Dense(EMBEDDING_DIM, activation=None, name=\"embedding\")(x)\n",
        "    outputs = layers.Dense(10, activation='softmax')(embeddings) # aplicando su clasificacion sobre 10 clases (estilos dado el dataset)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "t9SS26So09ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CALLBACKS\n",
        "\n",
        "*   early stopping\n",
        "*   reducción de LR\n",
        "*   evaluación de embeddings por época"
      ],
      "metadata": {
        "id": "i_vSO7hm2dQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_callbacks(phase, model=None, dataset=None):\n",
        "    base_callbacks =  [\n",
        "        callbacks.EarlyStopping(patience=3, restore_best_weights=True), # detiene el proceso de treno si presencia una NO mejoria\n",
        "        callbacks.ModelCheckpoint(f\"efficientnet_phase{phase}.keras\", save_best_only=True), # produce el binario por fase, para retomar sin reinicar todo\n",
        "        callbacks.ReduceLROnPlateau(factor=0.5, patience=2) # reducimos la tasa de aprendizaje en caso no mejores, aplica esto luego de 2 epocas sin mejora\n",
        "    ]\n",
        "\n",
        "    if model and dataset:\n",
        "        eval_callback = callbacks.LambdaCallback(\n",
        "            on_epoch_end=lambda epoch, logs: evaluate_embeddings(model, dataset, silent=True)\n",
        "        )\n",
        "        base_callbacks.append(eval_callback)\n",
        "\n",
        "    return base_callbacks"
      ],
      "metadata": {
        "id": "IlRtMlqf1A7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SCHEDULE DE LEARNING RATE TRIANGULAR\n",
        "Reduce gradualmente la tasa de aprendizaje para permitir rápido ascenso y luego descenso gradual, esto se da por fase (QUIZÁ UN POCO REDUNDANTE)"
      ],
      "metadata": {
        "id": "qcrlAB7H2ww3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def slanted_triangular_lr(max_lr, total_epochs):\n",
        "    def scheduler(epoch):\n",
        "        pct = epoch / total_epochs\n",
        "        if pct < 0.3:\n",
        "            return max_lr * (pct / 0.3)\n",
        "        else:\n",
        "            return max_lr * (1 - (pct - 0.3) / 0.7)\n",
        "    return scheduler"
      ],
      "metadata": {
        "id": "Te9Wbzrk1Daj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ENTRENAMIENTO"
      ],
      "metadata": {
        "id": "clIySuAo3EPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model():\n",
        "    train_ds, test_ds = load_datasets()\n",
        "\n",
        "    # FASE 1: Feature Extraction (RED CONGELADA)\n",
        "    model = build_model(trainable_layers=None)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-3), # tasa de aprendizaje probablemente muy alta para ser las capas primarias (generales) - la base\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    model.fit(train_ds, validation_data=test_ds, epochs=EPOCHS_PHASE1, callbacks=get_callbacks(1, model, test_ds), verbose=1)\n",
        "\n",
        "    # FASE 2: Gradual Unfreezing desde block6 (estimado: x últimas capas)\n",
        "    model = build_model(trainable_layers=25)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    lr_scheduler = callbacks.LearningRateScheduler(slanted_triangular_lr(1e-4, EPOCHS_PHASE2))\n",
        "    model.fit(train_ds, validation_data=test_ds, epochs=EPOCHS_PHASE2, callbacks=[lr_scheduler] + get_callbacks(2, model, test_ds), verbose=1)\n",
        "\n",
        "    # FASE 3: Full Fine-Tuning\n",
        "    model = build_model(trainable_layers=len(EfficientNetB2(weights='imagenet', include_top=False).layers))\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    model.fit(train_ds, validation_data=test_ds, epochs=EPOCHS_PHASE3, callbacks=get_callbacks(3, model, test_ds), verbose=1)\n",
        "\n",
        "    return model, test_ds"
      ],
      "metadata": {
        "id": "ssks3VDz1FeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EVALUACIÓN EMBEDDINGS\n",
        "Se extraen los embeddings desde la capa 'embedding' y se evalúan con silhouette y P@5."
      ],
      "metadata": {
        "id": "oqaul23T3Ou4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_embeddings(model, dataset, silent=False):\n",
        "    try:\n",
        "        feature_model = models.Model(inputs=model.input, outputs=model.get_layer(\"embedding\").output)\n",
        "        embeddings = feature_model.predict(dataset, verbose=0)\n",
        "        labels = np.concatenate([y.numpy() for _, y in dataset])\n",
        "\n",
        "        sil_score = silhouette_score(embeddings, labels) # mide separabilidad entre clusters, es decir que tan cercanos suelen estar entre los mismos estilos\n",
        "\n",
        "        nn = NearestNeighbors(n_neighbors=6, metric='cosine').fit(embeddings) # evalúa si los 5 vecinos más cercanos poseen misma etiqueta\n",
        "        distances, indices = nn.kneighbors(embeddings)\n",
        "\n",
        "        correct = 0\n",
        "        for i, neighbors in enumerate(indices):\n",
        "            true_label = labels[i]\n",
        "            retrieved_labels = labels[neighbors[1:]]\n",
        "            correct += np.sum(retrieved_labels == true_label)\n",
        "        precision_at_5 = correct / (len(labels) * 5)\n",
        "\n",
        "        if not silent:\n",
        "            print(f\"[Eval] Silhouette Score: {sil_score:.4f} | Precision@5: {precision_at_5:.4f}\")\n",
        "        else:\n",
        "            print(f\"[Epoch Eval] Silhouette={sil_score:.4f}, P@5={precision_at_5:.4f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[Eval] Error: {str(e)}\")"
      ],
      "metadata": {
        "id": "R4hnXIBM1HYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resultados"
      ],
      "metadata": {
        "id": "_7BCqLqFJyQe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accuracy\n",
        "![EfficientNet-B2](https://i.imgur.com/jJBtLli.png)\n",
        "\n",
        "* **Fase 1** muestra una rápida mejora tanto en entrenamiento como validación, alcanzando un aproximado 50% en validación.\n",
        "* **Fase 2**  mejora un poco más y supera ligeramente los resultados de la Fase 1\n",
        "* **Fase 3**, aunque mejora progresivamente, queda por debajo de las fases anteriores en precisión, especialmente en validación.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "0jXEICSPD8VB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss\n",
        "![EfficientNet-B2](https://i.imgur.com/stwnHHS.png)\n",
        "\n",
        "* **Fase 1** comienza con pérdida más baja en validación (\\1.6) y se estabiliza rápidamente.\n",
        "* **Fase 2** muestra una gran caída de pérdida en entrenamiento, aún asi la pérdida de validación se mantiene creciente, posible sobreajuste\n",
        "* **Fase 3** muestra pérdidas más altas, además  de una brecha constante entre entrenamiento y validación\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "iBXYgbXQD_wq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Precision@5\n",
        "![EfficientNet-B2](https://i.imgur.com/naOr8lf.png)\n",
        "\n",
        "* **Fase 1** el mejor de todas las fases, superando 0.43 en la última época.\n",
        "* **Fase 2** al inicio mejorapero no alcanza a la fase 1\n",
        "* **Fase 3** tiene el peor desempeño de las fases, inmejorable.\n",
        "\n",
        "Es decir los embeddings de la fase 1 son los más útiles para recuperación por similitud, y el ajuste fino aplicado luego pareciese desestabilizar las representaciones, haciendolo inutiles\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "3wUYm_WGEBgV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Silhouette Score\n",
        "![EfficientNet-B2](https://i.imgur.com/YVCxris.png)\n",
        "\n",
        "* Todos los valores son negativos, dado que las clases pueden estar solapadas o la representación aún no es muy discriminativa\n",
        "* **Fase 1** muestra mejoras suaves y es la única en llegar a un valor cercano a cero (+0.0006).\n",
        "* **Fase 2 y 3** empeoran consistentemente, lo que hace a los embeddings menos distinguibles\n",
        "\n",
        "Degradacion de calidad o representatividad de embeddings\n",
        "\n"
      ],
      "metadata": {
        "id": "WfO2Fq_FEDVm"
      }
    }
  ]
}