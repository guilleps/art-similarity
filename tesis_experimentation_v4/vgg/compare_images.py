import numpy as np
from scipy.spatial.distance import cosine
from sklearn.metrics.pairwise import cosine_similarity
import argparse
import sys
import os
from vgg19_extractor import VGG19EmbeddingExtractor


class ImageSimilarityComparator:

    def __init__(self, method="gram", layer="conv4_2", verbose=True):
        """
        Args:
            method: M√©todo de extracci√≥n ('gram', 'conv', 'fc')
            layer: Capa de la que extraer features
            verbose: Si mostrar informaci√≥n detallada
        """
        self.extractor = VGG19EmbeddingExtractor()
        self.method = method
        self.layer = layer
        self.verbose = verbose

        if verbose:
            print(f"Comparador inicializado:")
            print(f"  - M√©todo: {method}")
            print(f"  - Capa: {layer}")
            print(f"  - Device: {self.extractor.device}")
            print("-" * 50)

    def compute_cosine_similarity(self, embedding1, embedding2):
        """
        Calcula la similitud coseno entre dos embeddings.

        Args:
            embedding1: Primer embedding (numpy array)
            embedding2: Segundo embedding (numpy array)

        Returns:
            float: Similitud coseno entre -1 y 1
                   1 = id√©nticos
                   0 = ortogonales (sin relaci√≥n)
                   -1 = opuestos
        """
        # M√©todo 1: Usando scipy (devuelve distancia, no similitud)
        # cosine_distance = cosine(embedding1, embedding2)
        # similarity = 1 - cosine_distance

        # M√©todo 2 alternativo: Usando sklearn (m√°s directo)
        similarity_matrix = cosine_similarity([embedding1], [embedding2])
        similarity = similarity_matrix[0][0]

        return similarity

    def normalize_embedding(self, embedding):
        """
        Normaliza un embedding (L2 normalization).
        √ötil para hacer las comparaciones m√°s estables.

        Args:
            embedding: Embedding a normalizar

        Returns:
            Embedding normalizado
        """
        norm = np.linalg.norm(embedding)
        if norm == 0:
            return embedding
        return embedding / norm

    def compare_images(self, image_path1, image_path2, normalize=True):
        """
        Compara dos im√°genes y devuelve su similitud.

        Args:
            image_path1: Ruta a la primera imagen
            image_path2: Ruta a la segunda imagen
            normalize: Si normalizar los embeddings antes de comparar

        Returns:
            dict: Diccionario con resultados de similitud
        """
        # Verificar que las im√°genes existen
        if not os.path.exists(image_path1):
            raise FileNotFoundError(f"No se encontr√≥ la imagen: {image_path1}")
        if not os.path.exists(image_path2):
            raise FileNotFoundError(f"No se encontr√≥ la imagen: {image_path2}")

        if self.verbose:
            print(f"Procesando imagen 1: {os.path.basename(image_path1)}")

        # Extraer embedding de la primera imagen
        embedding1 = self.extractor.extract_embedding(
            image_path1, method=self.method, layer=self.layer
        )

        if self.verbose:
            print(f"  ‚úì Embedding 1 extra√≠do: shape={embedding1.shape}")
            print(f"\nProcesando imagen 2: {os.path.basename(image_path2)}")

        # Extraer embedding de la segunda imagen
        embedding2 = self.extractor.extract_embedding(
            image_path2, method=self.method, layer=self.layer
        )

        if self.verbose:
            print(f"  ‚úì Embedding 2 extra√≠do: shape={embedding2.shape}")

        # Normalizar si se requiere
        if normalize:
            embedding1 = self.normalize_embedding(embedding1)
            embedding2 = self.normalize_embedding(embedding2)
            if self.verbose:
                print(f"  ‚úì Embeddings normalizados")

        # Calcular similitud coseno
        similarity = self.compute_cosine_similarity(embedding1, embedding2)

        # Crear resultado
        results = {
            "similarity": similarity,
            "similarity_percentage": similarity * 100,
            "embedding1_shape": embedding1.shape,
            "embedding2_shape": embedding2.shape,
            "method": self.method,
            "layer": self.layer,
            "normalized": normalize,
        }

        return results

    def interpret_similarity(self, similarity):
        if similarity >= 0.95:
            return "Pr√°cticamente id√©nticas"
        elif similarity >= 0.85:
            return "Muy similares"
        elif similarity >= 0.70:
            return "Similares"
        elif similarity >= 0.50:
            return "Moderadamente similares"
        elif similarity >= 0.30:
            return "Poco similares"
        elif similarity >= 0.10:
            return "Muy poco similares"
        else:
            return "Diferentes"

    def compare_multiple_methods(self, image_path1, image_path2):
        """
        Compara dos im√°genes usando m√∫ltiples m√©todos/capas.

        Args:
            image_path1: Ruta a la primera imagen
            image_path2: Ruta a la segunda imagen

        Returns:
            dict: Resultados para cada m√©todo
        """
        comparisons = {}

        # Diferentes configuraciones a probar
        configs = [
            ("gram", "conv3_3", "Texturas finas"),
            ("gram", "conv4_2", "Patrones medios"),
            ("gram", "conv5_3", "Caracter√≠sticas abstractas"),
            ("conv", "conv4_2", "Features espaciales"),
            ("fc", "fc2", "Representaci√≥n sem√°ntica"),
        ]

        print("\n" + "=" * 60)
        print("COMPARACI√ìN MULTI-M√âTODO")
        print("=" * 60)

        for method, layer, description in configs:
            self.method = method
            self.layer = layer

            print(f"\n{description} ({method} - {layer}):")
            print("-" * 40)

            try:
                results = self.compare_images(image_path1, image_path2, normalize=True)

                similarity = results["similarity"]
                interpretation = self.interpret_similarity(similarity)

                print(f"  Similitud: {similarity:.4f} ({similarity*100:.2f}%)")
                print(f"  Interpretaci√≥n: {interpretation}")

                comparisons[f"{method}_{layer}"] = {
                    "similarity": similarity,
                    "description": description,
                    "interpretation": interpretation,
                }

            except Exception as e:
                print(f"  Error: {e}")
                comparisons[f"{method}_{layer}"] = None

        # Calcular promedio
        valid_similarities = [v["similarity"] for v in comparisons.values() if v]
        if valid_similarities:
            avg_similarity = np.mean(valid_similarities)
            print(f"\n{'='*60}")
            print(
                f"SIMILITUD PROMEDIO: {avg_similarity:.4f} ({avg_similarity*100:.2f}%)"
            )
            print(
                f"Interpretaci√≥n general: {self.interpret_similarity(avg_similarity)}"
            )
            print(f"{'='*60}")

        return comparisons


def main():
    """
    Funci√≥n principal con interfaz de l√≠nea de comandos.
    """
    parser = argparse.ArgumentParser(
        description="Compara la similitud entre dos im√°genes usando VGG-19",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Ejemplos de uso:
  python compare_images.py imagen1.jpg imagen2.jpg
  python compare_images.py imagen1.jpg imagen2.jpg --method gram --layer conv4_2
  python compare_images.py imagen1.jpg imagen2.jpg --all-methods
  python compare_images.py imagen1.jpg imagen2.jpg --quiet
        """,
    )

    parser.add_argument("image1", help="Ruta a la primera imagen")
    parser.add_argument("image2", help="Ruta a la segunda imagen")

    parser.add_argument(
        "--method",
        choices=["gram", "conv", "fc"],
        default="gram",
        help="M√©todo de extracci√≥n de embeddings (default: gram)",
    )

    parser.add_argument(
        "--layer",
        default="conv4_2",
        help="Capa de la que extraer features (default: conv4_2)",
    )

    parser.add_argument(
        "--no-normalize",
        action="store_true",
        help="No normalizar los embeddings antes de comparar",
    )

    parser.add_argument(
        "--all-methods",
        action="store_true",
        help="Comparar usando todos los m√©todos disponibles",
    )

    parser.add_argument(
        "--quiet",
        action="store_true",
        help="Modo silencioso, solo mostrar resultado final",
    )

    args = parser.parse_args()

    # Crear comparador
    comparator = ImageSimilarityComparator(
        method=args.method, layer=args.layer, verbose=not args.quiet
    )

    try:
        if args.all_methods:
            # Comparar con m√∫ltiples m√©todos
            results = comparator.compare_multiple_methods(args.image1, args.image2)
        else:
            # Comparaci√≥n simple
            if not args.quiet:
                print("\n" + "=" * 60)
                print("COMPARACI√ìN DE SIMILITUD ENTRE IM√ÅGENES")
                print("=" * 60)
                print(f"Imagen 1: {args.image1}")
                print(f"Imagen 2: {args.image2}")
                print("-" * 60)

            results = comparator.compare_images(
                args.image1, args.image2, normalize=not args.no_normalize
            )

            similarity = results["similarity"]
            interpretation = comparator.interpret_similarity(similarity)

            # Mostrar resultados
            if args.quiet:
                # Modo silencioso: solo el n√∫mero
                print(f"{similarity:.6f}")
            else:
                print("\n" + "=" * 60)
                print("RESULTADOS")
                print("=" * 60)
                print(f"üìä Similitud Coseno: {similarity:.6f} | üìà Porcentaje: {results['similarity_percentage']:.2f}%")
                print(f"üí° Interpretaci√≥n: {interpretation}")
                print("-" * 60)
                print(f"‚ÑπÔ∏è  M√©todo: {results['method']}")
                print(f"‚ÑπÔ∏è  Capa: {results['layer']}")
                print(f"‚ÑπÔ∏è  Normalizado: {'S√≠' if results['normalized'] else 'No'}")
                print(f"‚ÑπÔ∏è  Dimensiones embedding: {results['embedding1_shape'][0]}")
                print("=" * 60)

                # Escala visual
                print("\nESCALA DE SIMILITUD:")
                print("  0% ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 100%")
                print(
                    "  |"
                    + " " * int(similarity * 36)
                    + "‚ñì"
                    + " " * (36 - int(similarity * 36))
                    + "|"
                )
                print(f"  ‚îî‚îÄ> {similarity*100:.1f}% similar")

    except FileNotFoundError as e:
        print(f"‚ùå Error: {e}", file=sys.stderr)
        sys.exit(1)
    except Exception as e:
        print(f"‚ùå Error inesperado: {e}", file=sys.stderr)
        sys.exit(1)


# Funci√≥n de conveniencia para uso directo en Python
def compare_images_simple(image1_path, image2_path, method="gram", layer="conv4_2"):
    """
    Funci√≥n simple para comparar dos im√°genes.

    Args:
        image1_path: Ruta a la primera imagen
        image2_path: Ruta a la segunda imagen
        method: M√©todo de extracci√≥n ('gram', 'conv', 'fc')
        layer: Capa a usar

    Returns:
        float: Similitud coseno (0 a 1)

    Ejemplo:
        >>> similarity = compare_images_simple('foto1.jpg', 'foto2.jpg')
        >>> print(f"Las im√°genes son {similarity*100:.1f}% similares")
    """
    comparator = ImageSimilarityComparator(method=method, layer=layer, verbose=False)
    results = comparator.compare_images(image1_path, image2_path)
    return results["similarity"]


if __name__ == "__main__":
    main()
